{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879cd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Test GPU usage\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"✓ GPU detected and available\")\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([1.0, 2.0, 3.0])\n",
    "        b = tf.constant([4.0, 5.0, 6.0])\n",
    "        c = tf.add(a, b)\n",
    "        print(f\"GPU computation result: {c}\")\n",
    "else:\n",
    "    print(\"❌ No GPU available - using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This ipynb file is adapted from the previous ResNet training script\n",
    "Author: Jason Niow\n",
    "DtaeL \n",
    "'''\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "\n",
    "print(f'tensorflow version: {tf.__version__}')\n",
    "print(f'pandas version: {pd.__version__}')\n",
    "print(f'numpy version: {np.__version__}')\n",
    "print(f'seaborn version: {sns.__version__}')\n",
    "\n",
    "# check tensorflow GPU device support\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print('GPU present')\n",
    "else:\n",
    "    print('GPU absent')\n",
    "\n",
    "# paths to load datasets from\n",
    "train_store_path = 'C:/Users/UserAdmin/Desktop/Jason - Signal Classification/AI Models/Data/train_datasets/train_real_data_labelled'\n",
    "test_store_path = 'C:/Users/UserAdmin/Desktop/Jason - Signal Classification/AI Models/Data/test_datasets/test_jul22_real'\n",
    "\n",
    "# convert to pathlib Path objects\n",
    "train_dir = pathlib.Path(train_store_path)\n",
    "test_dir = pathlib.Path(test_store_path)\n",
    "\n",
    "# get list of datasets paths in dir\n",
    "train_ds_paths = sorted(list(train_dir.glob('*.csv')))\n",
    "test_ds_paths = sorted(list(test_dir.glob('*.csv')))\n",
    "\n",
    "\n",
    "# extract classification target from file names\n",
    "train_ds_type = np.array([x.parts[-1].split('_')[:2] for x in train_ds_paths])\n",
    "test_ds_type = np.array([x.parts[-1].split('_')[:2] for x in test_ds_paths])\n",
    "\n",
    "# Get list of classification labels of dataset e.g. 8CPSK, FM, 16qam\n",
    "train_ds_mod = [s.upper() for s in train_ds_type[:,0]]\n",
    "test_ds_mod = [s.upper() for s in test_ds_type[:,0]]\n",
    "\n",
    "# Get list of classification frequency\n",
    "train_ds_freq = [s.upper() for s in train_ds_type[:, 1]]\n",
    "test_ds_freq = [s.upper() for s in test_ds_type[:, 1]]\n",
    "\n",
    "# generate signal type tags\n",
    "known_signal_tags = {'16QAM', '8CPSK', 'FM'}\n",
    "signal_tags = {'16QAM': 0, '8CPSK': 1, 'FM': 2}\n",
    "# signal_tags = {k : i for i, k in enumerate(np.unique(sorted([s.upper() for s in train_ds_mod] + ['UNKNOWN'])))}\n",
    "\n",
    "print(signal_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5221bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the dataset(s)\n",
    "\n",
    "# load dataset information\n",
    "specs = []\n",
    "datasets = []\n",
    "\n",
    "for dataset_paths in [train_ds_paths, test_ds_paths]:\n",
    "    temp_ds = []\n",
    "    temp_specs = []\n",
    "\n",
    "    for path in dataset_paths:\n",
    "        print(f'loading {path}...', end=' ')\n",
    "\n",
    "        # load dataset details - Sampling frequency, Number of Samples, Number of Records\n",
    "        df_spec = pd.read_csv(path, nrows=10, header=None, index_col=0, names=['info'])\n",
    "        df_spec = df_spec.drop(['Version', 'DateTime', 'TimestampOffset', 'TriggerPosition', 'FastFrameID', 'IDInFastFrame', 'TotalInFastFrame'], axis=0).astype('int')\n",
    "\n",
    "        temp_specs.append(df_spec)\n",
    "\n",
    "        # load data, strip unnecessary bits out - I/Q data\n",
    "        df = pd.read_csv(path, skiprows=10, names=['I', 'Q'])\n",
    "\n",
    "        df = df.loc[~df['I'].isin(['TimestampOffset', 'TriggerPosition', 'FastFrameID', 'IDInFastFrame', 'TotalInFastFrame'])]\n",
    "        df['I'] = df['I'].astype('float')\n",
    "\n",
    "        print(f'loaded')\n",
    "\n",
    "        temp_ds.append(df)\n",
    "\n",
    "    datasets.append(temp_ds)\n",
    "    specs.append(temp_specs)\n",
    "\n",
    "print('done.')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rms_normalize(iq, target_rms=1.0, eps=1e-12, remove_dc=True):\n",
    "    \"\"\"\n",
    "    iq: complex64/complex128 numpy array, shape (N,)\n",
    "    target_rms: desired RMS after scaling\n",
    "    \"\"\"\n",
    "    x = iq.astype(np.complex64, copy=False)\n",
    "    if remove_dc:\n",
    "        x = x - x.mean()\n",
    "    rms = np.sqrt(np.mean(np.abs(x)**2) + eps)\n",
    "    return x * (target_rms / rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd14235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split dataset(s) into records, extract test dataset\n",
    "processed = []\n",
    "\n",
    "# number of test records to extract\n",
    "ntest = 100\n",
    "rlength = 1024\n",
    "nrecords = 1\n",
    "nsamples = 10000\n",
    "\n",
    "for h, dataset in enumerate(datasets): # loops through training, then testing\n",
    "    if h == 0:\n",
    "        dataset_type = 'TRAINING'\n",
    "    else: dataset_type = 'TESTING'\n",
    "    temp_processed = []\n",
    "    specs_df = specs[h]\n",
    "\n",
    "    print(f'\\nType\\t\\tLocation\\tTotal Records\\tSamples/Record')\n",
    "    # Loops through each data point in the dataset\n",
    "    for i in range(len(dataset)):\n",
    "        # nrecords = specs_df[i].loc['NumberRecords']['info'] if dataset_type == 'TRAINING' else 400 ### wtf is this\n",
    "        # nrecords = specs_df[i].loc['NumberRecords']['info']\n",
    "        # nsamples = specs_df[i].loc['NumberSamples']['info']\n",
    "\n",
    "        ds_length = dataset[i].shape[0]\n",
    "\n",
    "        # make life easier\n",
    "        ds_mod = train_ds_mod if dataset_type == 'TRAINING' else test_ds_mod\n",
    "        ds_freq = train_ds_freq if dataset_type == 'TRAINING' else test_ds_freq\n",
    "\n",
    "        # sanity check\n",
    "        print(f'{ds_mod[i]:<13}\\t{ds_freq[i]:<15}\\t{nrecords:<7}\\t\\t{nsamples:<7}')\n",
    "\n",
    "        # loop through dataset to split\n",
    "        for j in range(nrecords):\n",
    "            # extract sample length worth of samples for each record, then transpose for easier access later\n",
    "            # record = dataset[i].iloc[(nsamples * j):(nsamples * (j+1))].values.T\n",
    "            iq = dataset[i].iloc[(nsamples * j):(nsamples * (j+1))].values\n",
    "            iq_complex = iq[:, 0] + 1j * iq[:, 1]\n",
    "            iq_rms = rms_normalize(iq_complex, target_rms=1.0, remove_dc=False).T\n",
    "            i_rms = iq_rms.real.reshape((1, -1))\n",
    "            q_rms = iq_rms.imag.reshape((1, -1))\n",
    "            record = np.vstack((i_rms, q_rms))\n",
    "            # print(f\"Shape of record: {record.shape}\")\n",
    "            # pad shorter records with random padding to rlength\n",
    "            if nsamples < rlength:\n",
    "                print(f\"i: {i} j : {j} Sample length {nsamples} is lesser than {rlength}\")\n",
    "                # deterine pad amount\n",
    "                pad_length = rlength - nsamples\n",
    "                lpad_length = np.random.randint(0, pad_length+1)\n",
    "                rpad_length = pad_length - lpad_length\n",
    "\n",
    "                # generate pad\n",
    "                lpad = np.zeros((2, lpad_length))\n",
    "                rpad = np.zeros((2, rpad_length))\n",
    "\n",
    "                # concatenate pad\n",
    "                record = np.concatenate([lpad, record, rpad], axis=1)\n",
    "\n",
    "            # truncate longer records to rlength\n",
    "            elif nsamples > rlength:\n",
    "                # print(f\"i: {i} j : {j} Sample length {nsamples} is greater than {rlength}\")\n",
    "                record = record[:,:rlength]\n",
    "\n",
    "            # add processed record to list\n",
    "            signal_tag = signal_tags.get(ds_mod[i], 3) # 3 is for proxy OOD samples\n",
    "            # signal_tag = signal_tags[ds_mod[i].upper()]\n",
    "            temp_processed.append([ds_mod[i], signal_tag, ds_freq[i], record])\n",
    "\n",
    "    processed.append(temp_processed)\n",
    "\n",
    "# convert list into dataframes for later use, randomise, extract test records\n",
    "df_train = pd.DataFrame(processed[0], columns=['signal_type', 'tag', 'location', 'record']).sample(frac=1, random_state=42)\n",
    "df_test = pd.DataFrame(processed[1], columns=['signal_type', 'tag', 'location', 'record']).sample(frac=1, random_state=42)\n",
    "\n",
    "# print dataset statistics\n",
    "print(f'\\n{\"Stats\":^30}')\n",
    "print(f'Dataset\\tLength\\tRecords/Sample')\n",
    "print(f'Train\\t{df_train.shape[0]:<5}\\t{df_train[\"record\"].iloc[0].shape[1]}')\n",
    "print(f'Test\\t{df_test.shape[0]:<5}\\t{df_train[\"record\"].iloc[0].shape[1]}')\n",
    "\n",
    "\n",
    "# define one hot encode function\n",
    "def one_hot(arr, n_cat):\n",
    "    output = []\n",
    "    for n in arr:\n",
    "        if n == 3: # for proxy OOD samples\n",
    "            result = np.zeros(n_cat)\n",
    "        else: # for known classes\n",
    "            result = np.zeros(n_cat)\n",
    "            result[n] = 1\n",
    "\n",
    "        output.append(result)\n",
    "\n",
    "    return np.array(output, dtype=int)\n",
    "\n",
    "# extract train and test data\n",
    "X_train = np.concatenate(df_train['record'].values).reshape((df_train.shape[0], 2, rlength, 1))\n",
    "y_train = one_hot(df_train['tag'].values, len(signal_tags))\n",
    "y_ood = df_train['tag'] == 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_shape, latent_dim=64, output_shape=None):\n",
    "        super().__init__()\n",
    "        self.encoder = self.create_encoder(input_shape, latent_dim = 64)\n",
    "        self.decoder = self.create_decoder(latent_dim, output_shape=input_shape)\n",
    "\n",
    "    def create_encoder(self, input_shape, latent_dim):\n",
    "        input_layer = tf.keras.Input(shape=input_shape)\n",
    "        # res stacks\n",
    "        x = self.res_stack(input_layer, 512)\n",
    "        x = self.res_stack(x, 256)\n",
    "        x = self.res_stack(x, 128)\n",
    "        x = self.res_stack(x, 64)\n",
    "        x = self.res_stack(x, 32)\n",
    "        x = self.res_stack(x, 16)\n",
    "        \n",
    "        # Flatten and create latent representation\n",
    "        x = Flatten()(x)\n",
    "        latent = Dense(latent_dim, activation='linear', name='latent')(x)\n",
    "\n",
    "        return Model(inputs=input_layer, outputs=latent, name='encoder')\n",
    "\n",
    "    def create_decoder(self, latent_dim, output_shape):\n",
    "        input_layer = tf.keras.Input(shape=(latent_dim,))\n",
    "        \n",
    "        # Calculate the shape after the encoder's final pooling\n",
    "        # After 6 pooling operations (each divides by 2), and assuming input shape like (2, length, 1)\n",
    "        # We need to calculate what the spatial dimensions would be\n",
    "        height_after_pooling = output_shape[0] // (2**6)  # 6 pooling layers\n",
    "        width_after_pooling = output_shape[1] // (2**6)   # 6 pooling layers\n",
    "        \n",
    "        # If dimensions become 0, set minimum of 1\n",
    "        height_after_pooling = max(1, height_after_pooling)\n",
    "        width_after_pooling = max(1, width_after_pooling)\n",
    "        \n",
    "        # Dense layer to expand latent vector\n",
    "        x = Dense(height_after_pooling * width_after_pooling * 48, activation='relu')(input_layer)\n",
    "        x = Reshape((height_after_pooling, width_after_pooling, 48))(x)\n",
    "        \n",
    "        # Decoder stacks - mirror the encoder but with upsampling\n",
    "        x = self.decoder_stack(x, 16)\n",
    "        x = self.decoder_stack2(x, 32) \n",
    "        x = self.decoder_stack2(x, 64)\n",
    "        x = self.decoder_stack2(x, 128)\n",
    "        x = self.decoder_stack2(x, 256)\n",
    "        x = self.decoder_stack2(x, 512)\n",
    "        \n",
    "        # Final reconstruction layer\n",
    "        output = Conv2D(output_shape[-1], 3, activation='linear', padding='same', name='reconstruction')(x)\n",
    "        \n",
    "        return Model(inputs=input_layer, outputs=output, name='decoder')\n",
    "\n",
    "    def res_unit(self, x, dim, n):\n",
    "        for _ in range(n):\n",
    "            u = Conv2D(dim, 2, activation ='relu', padding='same')(x)\n",
    "            u = Conv2D(dim, 2, activation='linear', padding='same')(u)  # Fixed: apply to u, not x\n",
    "            # skip connection\n",
    "            x = concatenate([u, x])\n",
    "        return x\n",
    "    def res_stack(self, x, dim):\n",
    "        '''\n",
    "        function that creates a residual stack for the model\n",
    "\n",
    "        INPUT PARAMETERS\n",
    "        x: layer to connect to\n",
    "        dim: size of stack\n",
    "        '''\n",
    "\n",
    "        s = Conv2D(dim, 1, activation='linear', padding='same')(x)\n",
    "        s = self.res_unit(s, dim, 2)\n",
    "        s = MaxPooling2D(2, padding='same')(s)\n",
    "\n",
    "        return s\n",
    "    \n",
    "    def decoder_stack(self, x, dim):\n",
    "        '''\n",
    "        function that creates a decoder stack for reconstruction\n",
    "\n",
    "        INPUT PARAMETERS\n",
    "        x: layer to connect to\n",
    "        dim: size of stack (number of filters)\n",
    "        '''\n",
    "        # Upsample first\n",
    "        x = Conv2DTranspose(dim, 2, strides=2, activation='linear', padding='same')(x)\n",
    "        \n",
    "        # Apply residual units\n",
    "        s = Conv2D(dim, 1, activation='linear', padding='same')(x)\n",
    "        s = self.decoder_res_unit(s, dim, 2)\n",
    "        \n",
    "        return s\n",
    "\n",
    "    def decoder_stack2(self, x, dim):\n",
    "        '''\n",
    "        function that creates a decoder stack for reconstruction\n",
    "\n",
    "        INPUT PARAMETERS\n",
    "        x: layer to connect to\n",
    "        dim: size of stack (number of filters)\n",
    "        '''\n",
    "        # Upsample first\n",
    "        x = Conv2DTranspose(dim, 2, strides=(1,2), activation='linear', padding='same')(x)\n",
    "        \n",
    "        # Apply residual units\n",
    "        s = Conv2D(dim, 1, activation='linear', padding='same')(x)\n",
    "        s = self.decoder_res_unit(s, dim, 2)\n",
    "        \n",
    "        return s\n",
    "    \n",
    "    def decoder_res_unit(self, x, dim, n):\n",
    "        '''\n",
    "        Decoder residual unit - similar to res_unit but for decoder\n",
    "        '''\n",
    "        for _ in range(n):\n",
    "            u = Conv2D(dim, 2, activation='relu', padding='same')(x)\n",
    "            u = Conv2D(dim, 2, activation='linear', padding='same')(u)\n",
    "            # skip connection\n",
    "            x = concatenate([u, x])\n",
    "        return x\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        Forward pass through the autoencoder\n",
    "        '''\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def encode(self, inputs):\n",
    "        '''\n",
    "        Get the latent representation\n",
    "        '''\n",
    "        return self.encoder(inputs)\n",
    "    \n",
    "    def decode(self, latent):\n",
    "        '''\n",
    "        Reconstruct from latent representation\n",
    "        '''\n",
    "        return self.decoder(latent)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(input_shape=(2, 1024, 1), output_shape=(2, 1024, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the autoencoder model\n",
    "model = Autoencoder(input_shape=(2, 1024, 1), latent_dim=64)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',  # Mean Squared Error for reconstruction\n",
    "    metrics=['mae']  # Mean Absolute Error as additional metric\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Input shape: {model.encoder.input.shape}\")\n",
    "print(f\"Latent dimension: {model.encoder.output.shape}\")\n",
    "print(f\"Output shape: {model.decoder.output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Set up callbacks for better training\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Training configuration set up!\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Validation split: {VALIDATION_SPLIT}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and normalization\n",
    "print(\"Original data shape:\", X_train.shape)\n",
    "print(\"Data type:\", X_train.dtype)\n",
    "print(\"Data range: [{:.6f}, {:.6f}]\".format(X_train.min(), X_train.max()))\n",
    "\n",
    "# Normalize the data to [-1, 1] range for better training\n",
    "x_train_normalized = X_train.astype(np.float32)\n",
    "\n",
    "# Optional: Apply normalization (uncomment if needed)\n",
    "# x_train_normalized = (x_train_normalized - x_train_normalized.mean()) / x_train_normalized.std()\n",
    "\n",
    "# For autoencoder training, input and target are the same (reconstruction task)\n",
    "x_target = x_train_normalized.copy()\n",
    "\n",
    "print(\"Preprocessed data shape:\", x_train_normalized.shape)\n",
    "print(\"Target data shape:\", x_target.shape)\n",
    "print(\"Normalized data range: [{:.6f}, {:.6f}]\".format(x_train_normalized.min(), x_train_normalized.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49eb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "print(\"Starting autoencoder training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(\n",
    "    x_train_normalized,           # Input data\n",
    "    x_target,                     # Target data (same as input for autoencoder)\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation MAE\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot learning rate (if ReduceLROnPlateau was triggered)\n",
    "plt.subplot(1, 3, 3)\n",
    "if 'lr' in history.history:\n",
    "    plt.plot(history.history['lr'], label='Learning Rate')\n",
    "    plt.title('Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('LR')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No LR history available', \n",
    "             ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.title('Learning Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(f\"Final training loss: {history.history['loss'][-1]:.6f}\")\n",
    "print(f\"Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "print(f\"Final training MAE: {history.history['mae'][-1]:.6f}\")\n",
    "print(f\"Final validation MAE: {history.history['val_mae'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and show reconstruction examples\n",
    "print(\"Evaluating autoencoder performance...\")\n",
    "\n",
    "# Take a few samples for reconstruction testing\n",
    "n_samples = 5\n",
    "test_indices = np.random.choice(len(x_train_normalized), n_samples, replace=False)\n",
    "test_samples = x_train_normalized[test_indices]\n",
    "\n",
    "# Get reconstructions\n",
    "reconstructions = model.predict(test_samples)\n",
    "latent_representations = model.encode(test_samples)\n",
    "\n",
    "print(f\"Test samples shape: {test_samples.shape}\")\n",
    "print(f\"Reconstructions shape: {reconstructions.shape}\")\n",
    "print(f\"Latent representations shape: {latent_representations.shape}\")\n",
    "\n",
    "# Calculate reconstruction errors\n",
    "mse_errors = np.mean((test_samples - reconstructions)**2, axis=(1,2,3))\n",
    "mae_errors = np.mean(np.abs(test_samples - reconstructions), axis=(1,2,3))\n",
    "\n",
    "print(\"\\nReconstruction Errors:\")\n",
    "print(\"=\"*30)\n",
    "for i in range(n_samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  MSE: {mse_errors[i]:.6f}\")\n",
    "    print(f\"  MAE: {mae_errors[i]:.6f}\")\n",
    "\n",
    "print(f\"\\nAverage MSE: {np.mean(mse_errors):.6f}\")\n",
    "print(f\"Average MAE: {np.mean(mae_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original vs reconstructed IQ signals\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(min(3, n_samples)):  # Show first 3 samples\n",
    "    # I component (real part)\n",
    "    plt.subplot(3, 2, 2*i + 1)\n",
    "    plt.plot(test_samples[i, 0, :, 0], label='Original I', alpha=0.7)\n",
    "    plt.plot(reconstructions[i, 0, :, 0], label='Reconstructed I', alpha=0.7)\n",
    "    plt.title(f'Sample {i+1} - I Component')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Q component (imaginary part)\n",
    "    plt.subplot(3, 2, 2*i + 2)\n",
    "    plt.plot(test_samples[i, 1, :, 0], label='Original Q', alpha=0.7)\n",
    "    plt.plot(reconstructions[i, 1, :, 0], label='Reconstructed Q', alpha=0.7)\n",
    "    plt.title(f'Sample {i+1} - Q Component')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show latent space statistics\n",
    "print(\"\\nLatent Space Analysis:\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Latent dimension: {latent_representations.shape[1]}\")\n",
    "print(f\"Latent mean: {np.mean(latent_representations):.6f}\")\n",
    "print(f\"Latent std: {np.std(latent_representations):.6f}\")\n",
    "print(f\"Latent min: {np.min(latent_representations):.6f}\")\n",
    "print(f\"Latent max: {np.max(latent_representations):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = 'autoencoder_model'\n",
    "encoder_save_path = 'encoder_model' \n",
    "decoder_save_path = 'decoder_model'\n",
    "\n",
    "print(\"Saving trained models...\")\n",
    "\n",
    "# Save complete autoencoder\n",
    "model.save(model_save_path)\n",
    "print(f\"Complete autoencoder saved to: {model_save_path}\")\n",
    "\n",
    "# Save encoder and decoder separately\n",
    "model.encoder.save(encoder_save_path)\n",
    "print(f\"Encoder saved to: {encoder_save_path}\")\n",
    "\n",
    "model.decoder.save(decoder_save_path)\n",
    "print(f\"Decoder saved to: {decoder_save_path}\")\n",
    "\n",
    "# Save training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"Training history saved to: training_history.pkl\")\n",
    "\n",
    "print(\"\\nAll models and history saved successfully!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"\\nFinal Model Architecture:\")\n",
    "print(\"=\"*30)\n",
    "print(\"\\nEncoder Summary:\")\n",
    "model.encoder.summary()\n",
    "print(\"\\nDecoder Summary:\")\n",
    "model.decoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
